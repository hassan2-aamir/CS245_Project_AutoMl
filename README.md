# ğŸ¤– AutoML Classification System

A **Streamlit-based AutoML web application** that automates the complete machine learning workflow for classification tasks - from data upload to model deployment and real-time prediction.

## âœ¨ Features

- ğŸ“ **CSV Upload** with automatic encoding detection (UTF-8, Latin-1)
- ğŸ” **Automated EDA** with missing value analysis, outlier detection, correlation matrices
- âš ï¸ **Data Quality Detection** (class imbalance, high cardinality, constant features)
- ğŸ› ï¸ **User-Controlled Preprocessing** - you approve all fixes before they're applied
- ğŸ¤– **7 Classification Algorithms**: Logistic Regression, KNN, Decision Tree, Naive Bayes, Random Forest, SVM, Rule-Based
- âš¡ **Hyperparameter Tuning** with Grid Search or Randomized Search
- ğŸ“Š **Comprehensive Comparison** with Accuracy, Precision, Recall, F1, ROC-AUC
- ğŸ“„ **Detailed Reports** in HTML and Markdown format
- ğŸ¯ **Real-Time Prediction** with the best trained model

## ğŸš€ Quick Start

### Local Development

1. **Clone the repository**

   ```bash
   git clone <repository-url>
   cd AutoMl-FutureCashCow
   ```

2. **Create virtual environment**

   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. **Install dependencies**

   ```bash
   pip install -r requirements.txt
   ```

4. **Run the application**

   ```bash
   streamlit run streamlit_app.py
   ```

5. **Open browser** at `http://localhost:8501`

### Streamlit Cloud Deployment

1. Push code to GitHub
2. Connect repository to [Streamlit Cloud](https://streamlit.io/cloud)
3. Deploy with default settings (auto-detects `streamlit_app.py`)

## ğŸ“ Project Structure

```
â”œâ”€â”€ streamlit_app.py              # Main entry point
â”œâ”€â”€ requirements.txt              # Python dependencies
â”œâ”€â”€ README.md                     # This file
â”œâ”€â”€ pages/
â”‚   â”œâ”€â”€ 01_Upload_And_Info.py     # Dataset upload & metadata
â”‚   â”œâ”€â”€ 02_EDA_And_Issues.py      # EDA & issue detection
â”‚   â”œâ”€â”€ 03_Preprocess_And_Split.py # Preprocessing configuration
â”‚   â”œâ”€â”€ 04_Train_And_Tune.py      # Model training
â”‚   â”œâ”€â”€ 05_Compare_Report_Deploy.py # Comparison & reporting
â”‚   â””â”€â”€ 06_Prediction.py          # Real-time prediction
â”œâ”€â”€ ml/
â”‚   â”œâ”€â”€ data_loader.py            # CSV parsing & validation
â”‚   â”œâ”€â”€ eda.py                    # Exploratory data analysis
â”‚   â”œâ”€â”€ issue_detector.py         # Data quality detection
â”‚   â”œâ”€â”€ preprocessing.py          # Data preprocessing
â”‚   â”œâ”€â”€ models.py                 # Classification models
â”‚   â”œâ”€â”€ tuning.py                 # Hyperparameter optimization
â”‚   â”œâ”€â”€ evaluation.py             # Model evaluation
â”‚   â””â”€â”€ report_generator.py       # Report generation
â””â”€â”€ utils/
    â”œâ”€â”€ session_manager.py        # Session state helpers
    â”œâ”€â”€ validators.py             # Input validation
    â””â”€â”€ visualizations.py         # Plot utilities
```

## ğŸ”§ Workflow

1. **Upload Dataset** - Upload CSV file (max 200 MB)
2. **Explore Data** - View automated EDA and detected issues
3. **Approve Fixes** - Review and approve data quality fixes
4. **Configure Preprocessing** - Set scaling, encoding, train/test split
5. **Train Models** - Train 7 classifiers with hyperparameter tuning
6. **Compare Results** - View metrics, confusion matrices, ROC curves
7. **Generate Report** - Download comprehensive HTML/Markdown report
8. **Make Predictions** - Use the best model for new data

## ğŸ“Š Supported Algorithms

| Algorithm              | Description                             |
| ---------------------- | --------------------------------------- |
| Logistic Regression    | Linear classifier for binary/multiclass |
| K-Nearest Neighbors    | Distance-based classification           |
| Decision Tree          | Rule-based tree classifier              |
| Naive Bayes            | Probabilistic classifier (Gaussian)     |
| Random Forest          | Ensemble of decision trees              |
| Support Vector Machine | Margin-based classifier                 |
| Rule-Based             | Interpretable decision rules            |

## ğŸ“ˆ Evaluation Metrics

- **Accuracy** - Overall correctness
- **Precision** - Positive predictive value
- **Recall** - Sensitivity / True positive rate
- **F1-Score** - Harmonic mean of precision and recall (primary ranking metric)
- **ROC-AUC** - Area under ROC curve (binary classification only)
- **Confusion Matrix** - Detailed prediction breakdown

## âš™ï¸ Configuration

### File Constraints

- **Format**: CSV only
- **Max Size**: 200 MB
- **Encoding**: Auto-detected (UTF-8, Latin-1)

### Performance Targets

- **EDA**: â‰¤30 seconds for 100k rows
- **Training**: â‰¤15 minutes for 50k rows
- **Prediction**: â‰¤2 seconds response time

## ğŸ“ Target Users

- **Students** - Learning ML through hands-on experimentation
- **Researchers** - Quick model prototyping and comparison
- **Data Analysts** - Building classification models without coding
- **ML Practitioners** - Rapid baseline model evaluation

## ğŸ“ License

This project is developed as part of CS-245 Machine Learning course.

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit changes (`git commit -m 'Add AmazingFeature'`)
4. Push to branch (`git push origin feature/AmazingFeature`)
5. Open Pull Request

---

**Built with â¤ï¸ using Streamlit and scikit-learn**
